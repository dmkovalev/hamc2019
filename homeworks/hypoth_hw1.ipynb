{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "***\n",
    "\n",
    "We are going to work with the following dataset: fluid current in a tube.\n",
    "Some statistics are collected for dataset, incl. mean, skewness, kurtosis, etc. We are predicting flow rate ('tohn/hour'). We need to build confidence and predictive intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, preprocessing, model_selection\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exxsol_data.csv', sep=';', header=(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are 10 features and 1 label to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean' 'std' 'skew' 'kurt' 'RMS' 'crest' 'freq_peak' 'shan' 'perm' 'temp'\n",
      " 'tohn/hour']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['tohn/hour']\n",
    "freq_temp = df[['freq_peak','temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics tells us that flow rate is a function of a frequency peak and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_temp, y = shuffle(freq_temp, y)\n",
    "\n",
    "# split data into training and testing sets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_freq, test_freq, train_y, test_y = train_test_split(freq, y, train_size=0.7, random_state=2)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "predicted = model_selection.cross_val_predict(\n",
    "    lr, freq_temp, y.ravel(), cv=20)\n",
    "score = model_selection.cross_val_score(lr, freq_temp, y,\n",
    "                                         scoring='r2',cv=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q0: Build point estimate for mean r2 score and its deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r2 score:  0.8277067450774153\n",
      "its deviation:  0.05317070147409783\n"
     ]
    }
   ],
   "source": [
    "print('mean r2 score: ', score.mean())\n",
    "print('its deviation: ', score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Predicted is an array with predictions of the label y. Assuming, that $\\sigma = 0.1$, compute 95% confidence and predictive interval for mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictive: [-0.032932981351083135, 0.3590598155569277]\n",
      "confidence: [0.1556554495575848, 0.17047138464825973]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "se = np.power(y.values - predicted, 2)\n",
    "s = 0.1\n",
    "z = stats.norm.ppf(1 - (1 - 0.95) / 2)\n",
    "\n",
    "lower = err.mean() - z * s\n",
    "upper = err.mean() + z * s\n",
    "print('predictive: ' + str([lower, upper]))\n",
    "\n",
    "lower = err.mean() - z * s / np.sqrt(len(y))\n",
    "upper = err.mean() + z * s / np.sqrt(len(y))\n",
    "print('confidence: ' + str([lower, upper]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2:  Compute 95% confidence and predicted intervals for mean squared error, assuming no knowledge about $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictive: [-0.5225089655634272, 0.8486357997692717]\n",
      "confidence: [0.13715121667050556, 0.18897561753533898]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "se = np.power(y.values - predicted, 2)\n",
    "s = 0.1\n",
    "t = stats.t.ppf(1 - (1 - 0.95) / 2, len(y) - 1)\n",
    "\n",
    "lower = err.mean() - t * err.std()\n",
    "upper = err.mean() + t * err.std()\n",
    "print('predictive: ' + str([lower, upper]))\n",
    "\n",
    "lower = err.mean() - t * err.std() / np.sqrt(len(y))\n",
    "upper = err.mean() + t * err.std() / np.sqrt(len(y))\n",
    "print('confidence: ' + str([lower, upper]))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use additional features and more complex model, e.g. ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df['tohn/hour']\n",
    "X = df.drop(['tohn/hour'],axis=1)\n",
    "X = preprocessing.scale(X)\n",
    "X, y1 = shuffle(X, y1)\n",
    "\n",
    "encv = linear_model.ElasticNetCV(cv=10,max_iter=3000, n_alphas=10)\n",
    "predicted_encv = model_selection.cross_val_predict(\n",
    "    encv, X, y1.ravel(), cv=20)\n",
    "score_encv = model_selection.cross_val_score(encv,X, y1.ravel(),\n",
    "                                         scoring='r2',cv=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3:  Compute 95% confidence interval for difference in means of mean squared error between 2 models, assuming no knowledge about $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictive: [-0.4015691326294775, 0.6081227988004898]\n",
      "confidence: [0.0841954491472763, 0.12235821702373594]\n"
     ]
    }
   ],
   "source": [
    "se = np.power(y.values - predicted, 2)\n",
    "se_2 = np.power(y1.values - predicted_encv, 2)\n",
    "X_mean, Y_mean = np.mean(se), np.mean(se_2)\n",
    "std = np.sqrt(((len(se) - 1) * np.var(se, ddof=1) + (len(se_2) - 1) * np.var(se_2, ddof = 1)) / (len(se) + len(se) - 2))\n",
    "\n",
    "\n",
    "t2 = stats.t.ppf(1 - (1 - 0.95) / 2, (len(se) + len(se) - 2))\n",
    "\n",
    "lower = np.mean(se) - np.mean(se_2) - t * std\n",
    "upper = np.mean(se) - np.mean(se_2) + t * std\n",
    "print('predictive: ' + str([lower, upper]))\n",
    "\n",
    "lower = np.mean(se) - np.mean(se_2) - t * std / np.sqrt(len(y))\n",
    "upper = np.mean(se) - np.mean(se_2) + t * std / np.sqrt(len(y))\n",
    "print('confidence: ' + str([lower, upper]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
